{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0b44b-1def-4bf6-bfa5-d1b33d9173f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasketch\n",
    "import dask\n",
    "import dask_jobqueue\n",
    "import multiprocessing as mp\n",
    "from Bio import SeqIO\n",
    "import bitarray\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489938de-79ec-45bb-935e-0034b7004170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "treefile = '/scratch/dmoi/projects/covid/validation_data/covid19/gisaid_hcov-2020_08_25.QC.NSoutlier.filter.deMaiomask.aln.EPIID.treefile'\n",
    "alnfile = '/scratch/dmoi/projects/covid/validation_data/covid19/gisaid_hcov-2020_08_25.QC.NSoutlier.filter.deMaiomask.EPIID.aln'\n",
    "alnh5 = alnfile+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7eeac8-39fe-4693-b957-63a21e6c27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_seqs(fasta):\n",
    "    parsed = SeqIO.parse(fasta, 'fasta')\n",
    "    for seq in parsed:\n",
    "        #replace gaps\n",
    "        yield str(seq.seq).replace('-' ,'')\n",
    "\n",
    "def yield_aln(fasta):\n",
    "    parsed = SeqIO.parse(fasta, 'fasta')\n",
    "    for seq in parsed:\n",
    "        #replace gaps\n",
    "        yield str(seq.seq)\n",
    "\n",
    "def yield_ids(fasta):\n",
    "    parsed = SeqIO.parse(fasta, 'fasta')\n",
    "    for seq in parsed:\n",
    "        #replace gaps\n",
    "        yield str(seq.id)\n",
    "\n",
    "\n",
    "#kmer size mix for close and long range evolutionary distances\n",
    "def minhash_kmers( seq  , nperm = 3000 , windows = [30] ):\n",
    "    #generate the minhash signature for each genome.\n",
    "    h = datasketch.MinHash(num_perm = nperm  )\n",
    "    [h.update(seq[position:position+window].encode('utf8')) for window in windows for position in range(0, len(seq) - window) ]\n",
    "    return h.hashvalues\n",
    "\n",
    "def calc_chunk(seqiter, chunksize, pool ):\n",
    "    seqs = []\n",
    "    for i in range(chunksize):\n",
    "        try:\n",
    "            seqs.append(next(seqiter))\n",
    "        except:\n",
    "            pass\n",
    "    res = np.vstack( pool.map( minhash_kmers , seqs) )\n",
    "    return res\n",
    "#not sure if this will work but most splits should be valid...\n",
    "\n",
    "#@profile_me\n",
    "def get_masks(args,minvals = 1 , return_bitarray = True , verbose = False):\n",
    "    #col corresponds to hash function column in hash table \n",
    "    #not aln col!!!\n",
    "    i,col = args\n",
    "    masks = []\n",
    "    values, counts = np.unique(col, return_counts=True)\n",
    "    #informative hash function or else return None\n",
    "    if len(list(counts))>1:\n",
    "        #ascending values\n",
    "        for i,val in enumerate( list(values) ):\n",
    "            if counts[i]>1:\n",
    "                #get the fist mask w more than one leaf in it\n",
    "                m = bitarray.bitarray(list(col == val))\n",
    "                if m[0] != 1:\n",
    "                    m = ~m\n",
    "                if verbose == True:\n",
    "                    return m.to01()\n",
    "                if return_bitarray == True:\n",
    "                    return m.tolist()\n",
    "                else:\n",
    "                    return int( m.to01(  ) , 2 )\n",
    "                \n",
    "        return masks\n",
    "\n",
    "def yield_cols(hashfile):\n",
    "    with h5py.File(alnfile +'hashes.h5', 'r' ) as f:\n",
    "        ht = f['hashtable'][:]\n",
    "        for col in range(ht.shape[1]):\n",
    "            yield col,ht[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840f265d-50b9-4d16-b418-e656de172295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "(20, 2000)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#eyeball some decent kmer sizes\n",
    "seqiter = yield_seqs(alnfile)\n",
    "iditer = yield_ids(alnfile)\n",
    "\n",
    "test_set = []\n",
    "ids = []\n",
    "for i in range(20):\n",
    "    if i %10 ==0:\n",
    "        print(i)\n",
    "    t0 = time.time()\n",
    "    seq = next(seqiter)\n",
    "    seqid = next( iditer )\n",
    "    hashvals = minhash_kmers( seq  , nperm = 2000 , windows = [25,35,45] )\n",
    "    test_set.append( hashvals)\n",
    "    ids.append( seqid )\n",
    "\n",
    "test_set = np.vstack(test_set)\n",
    "def yield_col_np(ht):\n",
    "    for col in range(ht.shape[1]):\n",
    "        yield col,ht[:,col]\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddffeaf7-07af-47c1-9a32-714017822f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3a18f13d6fe4>:51: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  m = bitarray.bitarray(list(col == val))\n"
     ]
    }
   ],
   "source": [
    "totalmasks = list(map( get_masks , yield_col_np(test_set) ))\n",
    "totalmasks = [m for m in totalmasks if m]\n",
    "print(len(totalmasks))\n",
    "print(totalmasks[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd6ad5d-c92c-4655-adf4-acd3a538f7d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e04ed49e4376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/dmoi/miniconda/envs/ML/lib/python3.9/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    591\u001b[0m         '''\n\u001b[1;32m    592\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/dmoi/miniconda/envs/ML/lib/python3.9/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    677\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "mask_count = dict(collections.Counter(totalmasks))\n",
    "plt.hist(mask_count.values() , density = True )\n",
    "plt.show()\n",
    "plt.hist(mask_count.values() , density = False )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d224b409-bf6c-41a0-b4c4-914d0a6cf96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "featmat = np.vstack(totalmasks).T\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(featmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a0ff08-fe11-4b6c-aa12-0c95d7fe9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featmat2phylip(mat, IDs= None, filename='phylmat.txt'):\n",
    "    #each row is binary features for sequences\n",
    "    with open(filename,'w') as phylout:\n",
    "        phylout.write(str(mat.shape[0]) +' ' + str(mat.shape[1]) +'\\n')\n",
    "        for l in range(mat.shape[0]):\n",
    "            if IDs is not None:\n",
    "                outstr = IDs[l].split('_')[-1] +' ' +''.join([ str(b) for b in list(mat[l,:])])  +'\\n'\n",
    "            else:\n",
    "                outstr = str(l)+ ' ' +''.join([ str(b) for b in list(mat[l,:])]) +'\\n'\n",
    "            phylout.write(outstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1af58d97-1121-432f-99a5-a5fb4469396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "featmat2phylip(featmat , ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faa1082d-f107-4cec-bcce-3728e4c680be",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-78957d62c4c8>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-78957d62c4c8>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    cmd = path + 'iqtree -i ' +\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#run iqtree on binary and on dna\n",
    "\n",
    "import shlex\n",
    "from subprocess import Popen\n",
    "\n",
    "def loadmodules():\n",
    "    cmds = ['module load gcc' , 'module load ']\n",
    "    Popen(cmd, shell = True)\n",
    "\n",
    "def runFastTree(infile):\n",
    "    outfile = infile+'.tree'\n",
    "    cmd = 'VeryFastTree protein_alignment > ' + outfile\n",
    "    cmd = shlex.split(cmd)\n",
    "    return Popen(cmd)\n",
    "   \n",
    "def runiqtree(infile ,  binary = True):\n",
    "    path = '/scratch/dmoi/software/iqtree-1.6.12-Linux/bin/'\n",
    "    cmd = path + 'iqtree -i ' + \n",
    "    if binary == True:\n",
    "        cmd += ' '\n",
    "    else :\n",
    "        cmd += ' '\n",
    "    cmd = shlex.split(cmd)\n",
    "    return Popen( )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e47886a-6749-4f04-abce-9fcd20bf3a99",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-ba3acc459c73>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-ba3acc459c73>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    for iteration in\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nseqs = 20\n",
    "niter = 10\n",
    "alngen = yield_aln(alnfile)\n",
    "seqgen = yield_seqs(alnfile)\n",
    "\n",
    "for iteration in \n",
    "    sequences=[]\n",
    "    for i in range(nseqs):\n",
    "        #grab the aln lines\n",
    "        sequences.append(next(alngen))\n",
    "    #write to file\n",
    "    SeqIO.write(sequences, str(iteration)+'.fasta', 'fasta')\n",
    "    #run tree soft\n",
    "    \n",
    "    #run hash masks\n",
    "    for k in range(nseqs):\n",
    "        if i %10 ==0:\n",
    "        print(i)\n",
    "        seq = next(seqiter)\n",
    "        hashvals = minhash_kmers( seq  , nperm = 2000 , windows = [25,35,45] )\n",
    "        test_set.append( hashvals)\n",
    "        test_set = np.vstack(test_set)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67111fad-2cf8-4a93-8264-5ec872c0b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551e82d-616c-4ea3-afd6-1d008d57387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "hashes 2 hdf5 \n",
      "(480, 3000)\n",
      "(960, 3000)\n",
      "(1440, 3000)\n",
      "(1920, 3000)\n",
      "(2400, 3000)\n",
      "(2880, 3000)\n",
      "(3360, 3000)\n",
      "(3840, 3000)\n",
      "(4320, 3000)\n",
      "(4800, 3000)\n",
      "(5280, 3000)\n",
      "(5760, 3000)\n",
      "(6240, 3000)\n",
      "(6720, 3000)\n",
      "(7200, 3000)\n",
      "(7680, 3000)\n",
      "(8160, 3000)\n",
      "(8640, 3000)\n",
      "(9120, 3000)\n",
      "(9600, 3000)\n",
      "(10080, 3000)\n",
      "(10560, 3000)\n",
      "(11040, 3000)\n",
      "(11520, 3000)\n",
      "(12000, 3000)\n",
      "(12480, 3000)\n",
      "(12960, 3000)\n",
      "(13440, 3000)\n",
      "(13920, 3000)\n",
      "(14400, 3000)\n",
      "(14880, 3000)\n",
      "(15360, 3000)\n",
      "(15840, 3000)\n",
      "(16320, 3000)\n",
      "(16800, 3000)\n",
      "(17280, 3000)\n",
      "(17760, 3000)\n",
      "(18240, 3000)\n",
      "(18720, 3000)\n",
      "(19200, 3000)\n",
      "(19680, 3000)\n",
      "(20160, 3000)\n",
      "(20640, 3000)\n",
      "(21120, 3000)\n",
      "(21600, 3000)\n",
      "(22080, 3000)\n",
      "(22560, 3000)\n",
      "(23040, 3000)\n",
      "(23520, 3000)\n",
      "(24000, 3000)\n",
      "(24480, 3000)\n",
      "(24960, 3000)\n",
      "(25440, 3000)\n",
      "(25920, 3000)\n",
      "(26400, 3000)\n",
      "(26880, 3000)\n",
      "(27360, 3000)\n",
      "(27840, 3000)\n",
      "(28320, 3000)\n",
      "(28800, 3000)\n",
      "(29280, 3000)\n",
      "(29760, 3000)\n",
      "(30240, 3000)\n",
      "(30720, 3000)\n",
      "(31200, 3000)\n",
      "(31680, 3000)\n",
      "(32160, 3000)\n",
      "(32640, 3000)\n",
      "(33120, 3000)\n",
      "(33600, 3000)\n",
      "(34080, 3000)\n",
      "(34560, 3000)\n",
      "(35040, 3000)\n",
      "(35520, 3000)\n",
      "(36000, 3000)\n",
      "(36480, 3000)\n",
      "(36960, 3000)\n",
      "(37440, 3000)\n",
      "(37920, 3000)\n",
      "(38400, 3000)\n",
      "(38880, 3000)\n",
      "(39360, 3000)\n",
      "(39840, 3000)\n",
      "(40320, 3000)\n",
      "(40800, 3000)\n",
      "(41280, 3000)\n",
      "(41760, 3000)\n",
      "(42240, 3000)\n",
      "(42720, 3000)\n",
      "(43200, 3000)\n",
      "(43680, 3000)\n",
      "(44160, 3000)\n",
      "(44640, 3000)\n",
      "(45120, 3000)\n",
      "(45600, 3000)\n",
      "(46080, 3000)\n",
      "(46560, 3000)\n",
      "(47040, 3000)\n",
      "(47520, 3000)\n",
      "(48000, 3000)\n",
      "(48480, 3000)\n",
      "(48960, 3000)\n",
      "(49440, 3000)\n",
      "(49920, 3000)\n",
      "(50400, 3000)\n",
      "(50880, 3000)\n",
      "(51360, 3000)\n"
     ]
    }
   ],
   "source": [
    "overwrite = True\n",
    "nperm = 3000\n",
    "row_count = 0\n",
    "import pdb\n",
    "\n",
    "batchsize = 10 * mp.cpu_count()\n",
    "print(batchsize)\n",
    "\n",
    "maxshape = (10000000, nperm)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = mp.Pool()\n",
    "    #kmer size mix for close and long range evolutionary distances\n",
    "    def minhash_kmers( seq  , nperm = 10000 , windows = [25,30,35,40] ):\n",
    "        #generate the minhash signature for each genome.\n",
    "        h = datasketch.MinHash(num_perm = nperm  )\n",
    "        [h.update(seq[position:position+window].encode('utf8')) for window in windows for position in range(0, len(seq) - window) ]\n",
    "        return h.hashvalues\n",
    "\n",
    "    def calc_chunk(seqiter, chunksize, pool ):\n",
    "        seqs = []\n",
    "        for i in range(chunksize):\n",
    "            try:\n",
    "                seqs.append(next(seqiter))\n",
    "            except:\n",
    "                pass\n",
    "        res = np.vstack( pool.map( minhash_kmers , seqs) )\n",
    "        return res\n",
    "\n",
    "    if os.path.exists(alnfile+'_30'+'_hashes.h5') and overwrite == False:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            os.remove(alnfile +'hashes.h5')\n",
    "        except:\n",
    "            print('err delfile')\n",
    "        print('hashes 2 hdf5 ')\n",
    "        with h5py.File(alnfile +'hashes.h5', 'w' ) as f:\n",
    "            dset = f.create_dataset('hashtable', shape=(0,nperm), maxshape=maxshape, chunks=(batchsize,nperm), dtype=np.int32 )\n",
    "            seqiter = yield_seqs(alnfile)\n",
    "            start = False\n",
    "            count = 0\n",
    "            while  start == False or chunk.shape[0]> 0:\n",
    "                start = True\n",
    "                chunk = calc_chunk( seqiter , batchsize , pool )                \n",
    "                start = dset.shape[0]\n",
    "                dset.resize(dset.shape[0] + chunk.shape[0], axis=0)\n",
    "                dset[start:start+chunk.shape[0] ] = chunk   \n",
    "                print(dset.shape)\n",
    "        print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5eb8ac-2107-47d0-8e66-3900d4891ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#stab at an NJ algo\n",
    "\n",
    "#instead of pairwise use a 3rd as outgroup to generate the most likely\n",
    "#if larger than pairwise just use subtree\n",
    "\n",
    "\n",
    "def consensus(subtree,alnarray,consensusarray):\n",
    "    #calc consensus sequence from subtree nodes\n",
    "    index = [ rowIndex[l.name] for l in subtree.leaves()]\n",
    "    #some algo to find a consensus sequence here\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    To obtain the consensus, the sequence weights and a scoring matrix are used to \n",
    "    calculate a score at each position in the alignment as follows. The residue (or nucleotide\n",
    "    ) i in an alignment column, is compared to all other residues \n",
    "    (j) in the same column. The score for i is the sum over all residues j (not i=j) \n",
    "    of the score(ij)*weight(j), where score(ij) is taken from a nucleotide or protein scoring \n",
    "    matrix (see -datafile qualifier) and the \"weight(j)\" is the weighting given to the sequence j,\n",
    "    which is given in the alignment file.\n",
    "\n",
    "    The highest scoring type of residue is then found in the column. If the number of \"positive matches\"\n",
    "    (see below) for this residue is greater than the \"plurality value\" (see below), then this residue \n",
    "    is the consensus residue. Otherwise there is no consensus for that position and an 'n' \n",
    "    (nucleotide sequence alignment) or an 'x' (protein sequence alignment) character is written to \n",
    "    the consensus sequence.\n",
    "    \n",
    "    \"\"\"\n",
    "    seq= b''\n",
    "    submat = alnarray[index,:]\n",
    "    for col in submat.shape[1]:\n",
    "        symbols, counts = np.unique(submat[:,col] return_counts = True)\n",
    "        #select largest and append\n",
    "        seq+= \n",
    "        \n",
    "    return consensusID , consensusSeq\n",
    "\n",
    "def storeconsensus(storage, consensusID , consensusSeq):\n",
    "    #generate a fasta of the consensus sequences at each step\n",
    "    storage[consensusID] = consensusSeq\n",
    "\n",
    "def delconsensus( storage, forest , consensusID  ):\n",
    "    #you only need the nodes within the current round\n",
    "    #no use storing the consensus seqs if you dont have the mem\n",
    "    del storage[consensusID]\n",
    "    remove_lsh_treenode(consensusID, forest)\n",
    "    \n",
    "def lsh_query( treenode , hashvals, lshforest, k = 3 ):\n",
    "    #find the closest nodes\n",
    "    return lshforest.query( hashvals[rowindex[treenode],:] )\n",
    "\n",
    "\n",
    "def branchlen(n1,n2, hashvals , nperm):\n",
    "    h1=datasketch.MinHash( nperm = , hashvalues = hashvalues)\n",
    "    h2=datasketch.MinHash( nperm = , hashvalues = hashvalues)\n",
    "    return h1.jaccard(h2)\n",
    "    \n",
    "def add_hash(hasvals, forest , rowIndex ):\n",
    "    \n",
    "    \n",
    "    \n",
    "def remove_lsh_treenode(key, forest):\n",
    "        '''\n",
    "        Remove the key from the index.\n",
    "\n",
    "        Args:\n",
    "            key (hashable): The unique identifier of a set.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if key not in forest.keys:\n",
    "            raise ValueError(\"The given key does not exist\")\n",
    "        for H, hashtable in zip(self.keys[key], forest.hashtables):\n",
    "            hashtable.remove_val(H, key)\n",
    "            if not hashtable.get(H):\n",
    "                hashtable.remove(H)\n",
    "        forest.keys.remove(key)\n",
    "\n",
    "\n",
    "def add_treenode ()\n",
    "#find closest node\n",
    "\n",
    "#generate \n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772e409-92fb-42e4-a0b5-289c66ce286b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d09c9-932f-48ab-9cf3-cb2b2bbf4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get label for each seq\n",
    "parsed = SeqIO.parse(alnfile, 'fasta')\n",
    "seq2row = { seq.id:i for i,seq in enumerate(parsed) }\n",
    "row2seq = dict(zip ( seq2row.values() , seq2row.keys() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004623ed-2e66-42ad-986a-dde5082820bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import functools\n",
    "import pstats\n",
    "import tempfile\n",
    "def profile_me(func):\n",
    "    @functools.wraps(func)\n",
    "    def wraps(*args, **kwargs):\n",
    "        file = tempfile.mktemp()\n",
    "        profiler = cProfile.Profile()\n",
    "        profiler.runcall(func, *args, **kwargs)\n",
    "        profiler.dump_stats(file)\n",
    "        metrics = pstats.Stats(file)\n",
    "        metrics.strip_dirs().sort_stats('time').print_stats(100)\n",
    "    return wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5192bceb-0527-43b5-ae10-59ff858958c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mker higher than the min in may have been in signatures with a lower value in this column...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af53ef6-49ac-4b1e-b224-bf78093ae099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3057446-1e5f-4739-a637-d80a0b219c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "minvals = 1\n",
    "create_masks = True\n",
    "\n",
    "#each col is a mask \n",
    "branch_count = 0\n",
    "allcounts = []\n",
    "minvalcounts = []\n",
    "masks={}\n",
    "\n",
    "print(alnfile +'hashes.h5')\n",
    "\n",
    "with h5py.File(alnfile +'hashes.h5', 'r' ) as f:\n",
    "        ht = f['hashtable']\n",
    "        num_tasks = ht.shape[1]\n",
    "\n",
    "print('masks to generate' , num_tasks)\n",
    "coliterator = yield_cols(alnfile +'hashes.h5')\n",
    "totalmasks =[]\n",
    "pool = mp.Pool()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for i, masks in enumerate(pool.imap_unordered( get_masks , coliterator), 1):\n",
    "        totalmasks.append(masks)\n",
    "        if i%1000 == 0:\n",
    "            print('saving', len(totalmasks))\n",
    "            with open('masks.pkl' , 'wb') as pklout:\n",
    "                pklout.write(pickle.dumps(totalmasks))\n",
    "        if i%1000 == 0:\n",
    "            print('\\rdone {0:%}'.format(i/num_tasks))\n",
    "pool.close()\n",
    "totalmasks = [m for m in totalmasks if m]\n",
    "featmat = np.vstack(totalmasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0721a710-7833-4ecf-b5f2-fea5817ec1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "featmat2phylip(featmat.T  , filename = 'bigphylmat.txt')\n",
    "\n",
    "#filter trivial masks\n",
    "totalmasks = [m for m in totalmasks if m]\n",
    "with open('masks.pkl' , 'wb') as pklout:\n",
    "    pklout.write(pickle.dumps(totalmasks))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84380566-589e-4994-93d4-d1893152a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49025  28311 117730 ...  14743 218464  32456]\n",
      " [ 49025  28311 117730 ...  14743 218464  32456]\n",
      " [ 49025  28311 117730 ...  14743 218464  32456]\n",
      " ...\n",
      " [ 49025  28311 117730 ...  14743 218464  32456]\n",
      " [ 49025  28311 117730 ...  14743 218464  32456]\n",
      " [ 49025  28311 117730 ...  14743 218464  32456]]\n"
     ]
    }
   ],
   "source": [
    "print(featmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e748912f-f6cd-4999-8816-fc2a1415683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "mask_count = dict(collections.Counter(totalmasks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "602e4f32-3158-437b-94cb-d6283cc349eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2731.,    0.,    0.,    0.,    0.,  124.,    0.,    0.,    0.,\n",
       "           7.]),\n",
       " array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mask_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7800e-c8f1-492e-9870-f51ab47f0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(ht.shape[1] * frac)\n",
    "\n",
    "masks = { m:masks[m]  for m in masks if masks[m] > cutoff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef4c7092-bb6f-44b5-8ad7-5906ee6f9fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d3eb8-23e8-4f50-900a-29633d520e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tns = TaxonNamespace()\n",
    "for i in range(r.shape[0]):\n",
    "    tns.add_taxon(Taxon(seq_ids[i]))\n",
    "\n",
    "\n",
    "t = Tree.from_split_bitmasks(splits, tns)\n",
    "with open(f'{out_fn}.nwk', 'wt') as fp:\n",
    "    print(t.as_string('newick', suppress_rooting=True, unquoted_underscores=True), file=fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcc87ec-9eca-4d5d-aee8-2b1c7b0312a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2013 by Yanbo Ye (yeyanbo289@gmail.com)\n",
    "#\n",
    "# This file is part of the Biopython distribution and governed by your\n",
    "# choice of the \"Biopython License Agreement\" or the \"BSD 3-Clause License\".\n",
    "# Please see the LICENSE file that should have been included as part of this\n",
    "# package.\n",
    "\n",
    "\"\"\"Classes and methods for finding consensus trees.\n",
    "This module contains a ``_BitString`` class to assist the consensus tree\n",
    "searching and some common consensus algorithms such as strict, majority rule and\n",
    "adam consensus.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "import bitarray\n",
    "\n",
    "\n",
    "from ast import literal_eval\n",
    "from Bio.Phylo import BaseTree\n",
    "\n",
    "\n",
    "class _BitString(str):\n",
    "    \"\"\"Helper class for binary string data (PRIVATE).\n",
    "    Assistant class of binary string data used for storing and\n",
    "    counting compatible clades in consensus tree searching. It includes\n",
    "    some binary manipulation(&|^~) methods.\n",
    "    _BitString is a sub-class of ``str`` object that only accepts two\n",
    "    characters('0' and '1'), with additional functions for binary-like\n",
    "    manipulation(&|^~). It is used to count and store the clades in\n",
    "    multiple trees in consensus tree searching. During counting, the\n",
    "    clades will be considered the same if their terminals(in terms of\n",
    "    ``name`` attribute) are the same.\n",
    "    For example, let's say two trees are provided as below to search\n",
    "    their strict consensus tree::\n",
    "        tree1: (((A, B), C),(D, E))\n",
    "        tree2: ((A, (B, C)),(D, E))\n",
    "    For both trees, a _BitString object '11111' will represent their\n",
    "    root clade. Each '1' stands for the terminal clade in the list\n",
    "    [A, B, C, D, E](the order might not be the same, it's determined\n",
    "    by the ``get_terminal`` method of the first tree provided). For\n",
    "    the clade ((A, B), C) in tree1 and (A, (B, C)) in tree2, they both\n",
    "    can be represented by '11100'. Similarly, '11000' represents clade\n",
    "    (A, B) in tree1, '01100' represents clade (B, C) in tree2, and '00011'\n",
    "    represents clade (D, E) in both trees.\n",
    "    So, with the ``_count_clades`` function in this module, finally we\n",
    "    can get the clade counts and their _BitString representation as follows\n",
    "    (the root and terminals are omitted)::\n",
    "        clade   _BitString   count\n",
    "        ABC     '11100'     2\n",
    "        DE      '00011'     2\n",
    "        AB      '11000'     1\n",
    "        BC      '01100'     1\n",
    "    To get the _BitString representation of a clade, we can use the following\n",
    "    code snippet::\n",
    "        # suppose we are provided with a tree list, the first thing to do is\n",
    "        # to get all the terminal names in the first tree\n",
    "        term_names = [term.name for term in trees[0].get_terminals()]\n",
    "        # for a specific clade in any of the tree, also get its terminal names\n",
    "        clade_term_names = [term.name for term in clade.get_terminals()]\n",
    "        # then create a boolean list\n",
    "        boolvals = [name in clade_term_names for name in term_names]\n",
    "        # create the string version and pass it to _BitString\n",
    "        bitstr = _BitString(''.join(map(str, map(int, boolvals))))\n",
    "        # or, equivalently:\n",
    "        bitstr = _BitString.from_bool(boolvals)\n",
    "    To convert back::\n",
    "        # get all the terminal clades of the first tree\n",
    "        terms = [term for term in trees[0].get_terminals()]\n",
    "        # get the index of terminal clades in bitstr\n",
    "        index_list = bitstr.index_one()\n",
    "        # get all terminal clades by index\n",
    "        clade_terms = [terms[i] for i in index_list]\n",
    "        # create a new calde and append all the terminal clades\n",
    "        new_clade = BaseTree.Clade()\n",
    "        new_clade.clades.extend(clade_terms)\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from Bio.Phylo.Consensus import _BitString\n",
    "    >>> bitstr1 = _BitString('11111')\n",
    "    >>> bitstr2 = _BitString('11100')\n",
    "    >>> bitstr3 = _BitString('01101')\n",
    "    >>> bitstr1\n",
    "    _BitString('11111')\n",
    "    >>> bitstr2 & bitstr3\n",
    "    _BitString('01100')\n",
    "    >>> bitstr2 | bitstr3\n",
    "    _BitString('11101')\n",
    "    >>> bitstr2 ^ bitstr3\n",
    "    _BitString('10001')\n",
    "    >>> bitstr2.index_one()\n",
    "    [0, 1, 2]\n",
    "    >>> bitstr3.index_one()\n",
    "    [1, 2, 4]\n",
    "    >>> bitstr3.index_zero()\n",
    "    [0, 3]\n",
    "    >>> bitstr1.contains(bitstr2)\n",
    "    True\n",
    "    >>> bitstr2.contains(bitstr3)\n",
    "    False\n",
    "    >>> bitstr2.independent(bitstr3)\n",
    "    False\n",
    "    >>> bitstr1.iscompatible(bitstr2)\n",
    "    True\n",
    "    >>> bitstr2.iscompatible(bitstr3)\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    #todo: replace the .to01() by nice bitwise operations\n",
    "    def __init__(self,strdata):\n",
    "\n",
    "        \"\"\"Init from a binary string data.\"\"\"\n",
    "        if isinstance(strdata, str):\n",
    "            self.fixed_len = len(strdata)\n",
    "            self.pad = bitarray.bitarray(self.fixed_len)\n",
    "            self.bitarray = bitarray.bitarray(strdata)\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"The input should be a binary string composed of '0' and '1'\"\n",
    "            )\n",
    "        \n",
    "\n",
    "    def __and__(self, other):\n",
    "        result = self.bitarray & other.bitarray\n",
    "        return result & self.pad\n",
    "    \n",
    "    def __or__(self, other):\n",
    "        result = self.bitarray | other.bitarray\n",
    "        return self.pad&result\n",
    "\n",
    "    def __xor__(self, other):\n",
    "        resultint = self.selfint ^ other.bitarray\n",
    "        return self.pad&result\n",
    "\n",
    "    def __rand__(self, other):\n",
    "        result = self.bitarray & other.bitarray\n",
    "        return pad&result\n",
    "\n",
    "    def __ror__(self, other):\n",
    "        result = self.bitarray | other.bitarray\n",
    "        return self.pad&result\n",
    "\n",
    "    \n",
    "    def __rxor__(self, other):\n",
    "        resultint = self.bitarray ^ other.bitarray\n",
    "        return self.pad&result\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"_BitString(\" + self.to01() + \")\"\n",
    "\n",
    "    def index_one(self):\n",
    "        \"\"\"Return a list of positions where the element is '1'.\"\"\"\n",
    "        return [i for i, n in enumerate(self.bitarray.to01()) if n == \"1\"]\n",
    "\n",
    "    def index_zero(self):\n",
    "        \"\"\"Return a list of positions where the element is '0'.\"\"\"\n",
    "        return [i for i, n in enumerate(self.bitarray.to01()) if n == \"0\"]\n",
    "\n",
    "    def contains(self, other):\n",
    "        \"\"\"Check if current bitstr1 contains another one bitstr2.\n",
    "        That is to say, the bitstr2.index_one() is a subset of\n",
    "        bitstr1.index_one().\n",
    "        Examples:\n",
    "            \"011011\" contains \"011000\", \"011001\", \"000011\"\n",
    "        Be careful, \"011011\" also contains \"000000\". Actually, all _BitString\n",
    "        objects contain all-zero _BitString of the same length.\n",
    "        \"\"\"\n",
    "        return -1<self.bitarray.find(other.bitarray, start=0, stop= self.fixed_len)\n",
    "    \n",
    "    def independent(self, other):\n",
    "        \"\"\"Check if current bitstr1 is independent of another one bitstr2.\n",
    "        That is to say the bitstr1.index_one() and bitstr2.index_one() have\n",
    "        no intersection.\n",
    "        Be careful, all _BitString objects are independent of all-zero _BitString\n",
    "        of the same length.\n",
    "        \"\"\"\n",
    "        xorbit = self ^ other\n",
    "        return xorbit.bitarray.to01().count(\"1\") == self.bitarray.to01().count(\"1\") + other.bitarray.to01().count(\"1\")\n",
    "\n",
    "    def iscompatible(self, other):\n",
    "        \"\"\"Check if current bitstr1 is compatible with another bitstr2.\n",
    "        Two conditions are considered as compatible:\n",
    "         1. bitstr1.contain(bitstr2) or vise versa;\n",
    "         2. bitstr1.independent(bitstr2).\n",
    "        \"\"\"\n",
    "        return self.contains(other) or other.contains(self) or self.independent(other)\n",
    "\n",
    "    @classmethod\n",
    "    def from_bool(cls, bools):\n",
    "        return cls(bools)\n",
    "\n",
    "#### end of bit helper stuff ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6596b05d-7b78-4d21-846b-e1920814b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_consensus(trees, cutoff=0):\n",
    "    \"\"\"Search majority rule consensus tree from multiple trees.\n",
    "    This is a extend majority rule method, which means the you can set any\n",
    "    cutoff between 0 ~ 1 instead of 0.5. The default value of cutoff is 0 to\n",
    "    create a relaxed binary consensus tree in any condition (as long as one of\n",
    "    the provided trees is a binary tree). The branch length of each consensus\n",
    "    clade in the result consensus tree is the average length of all counts for\n",
    "    that clade.\n",
    "    :Parameters:\n",
    "        trees : iterable\n",
    "            iterable of trees to produce consensus tree.\n",
    "    \"\"\"\n",
    "    tree_iter = iter(trees)\n",
    "    first_tree = next(tree_iter)\n",
    "\n",
    "    terms = first_tree.get_terminals()\n",
    "    bitstr_counts, tree_count = _count_clades(itertools.chain([first_tree], tree_iter))\n",
    "\n",
    "    # Sort bitstrs by descending #occurrences, then #tips, then tip order\n",
    "    bitstrs = sorted(\n",
    "        bitstr_counts.keys(),\n",
    "        key=lambda bitstr: (bitstr_counts[bitstr][0], bitstr.count(\"1\"), str(bitstr)),\n",
    "        reverse=True,\n",
    "    )\n",
    "    root = BaseTree.Clade()\n",
    "    if bitstrs[0].count(\"1\") == len(terms):\n",
    "        root.clades.extend(terms)\n",
    "    else:\n",
    "        raise ValueError(\"Taxons in provided trees should be consistent\")\n",
    "    # Make a bitstr-to-clades dict and store root clade\n",
    "    bitstr_clades = {bitstrs[0]: root}\n",
    "    # create inner clades\n",
    "    for bitstr in bitstrs[1:]:\n",
    "        # apply majority rule\n",
    "        count_in_trees, branch_length_sum = bitstr_counts[bitstr]\n",
    "        confidence = 100.0 * count_in_trees / tree_count\n",
    "        if confidence < cutoff * 100.0:\n",
    "            break\n",
    "        clade_terms = [terms[i] for i in bitstr.index_one()]\n",
    "        clade = BaseTree.Clade()\n",
    "        clade.clades.extend(clade_terms)\n",
    "        clade.confidence = confidence\n",
    "        clade.branch_length = branch_length_sum / count_in_trees\n",
    "        bsckeys = sorted(bitstr_clades, key=lambda bs: bs.count(\"1\"), reverse=True)\n",
    "\n",
    "        # check if current clade is compatible with previous clades and\n",
    "        # record its possible parent and child clades.\n",
    "        compatible = True\n",
    "        parent_bitstr = None\n",
    "        child_bitstrs = []  # multiple independent childs\n",
    "        for bs in bsckeys:\n",
    "            if not bs.iscompatible(bitstr):\n",
    "                compatible = False\n",
    "                break\n",
    "            # assign the closest ancestor as its parent\n",
    "            # as bsckeys is sorted, it should be the last one\n",
    "            if bs.contains(bitstr):\n",
    "                parent_bitstr = bs\n",
    "            # assign the closest descendant as its child\n",
    "            # the largest and independent clades\n",
    "            if (\n",
    "                bitstr.contains(bs)\n",
    "                and bs != bitstr\n",
    "                and all(c.independent(bs) for c in child_bitstrs)\n",
    "            ):\n",
    "                child_bitstrs.append(bs)\n",
    "        if not compatible:\n",
    "            continue\n",
    "\n",
    "        if parent_bitstr:\n",
    "            # insert current clade; remove old bitstring\n",
    "            parent_clade = bitstr_clades.pop(parent_bitstr)\n",
    "            # update parent clade childs\n",
    "            parent_clade.clades = [\n",
    "                c for c in parent_clade.clades if c not in clade_terms\n",
    "            ]\n",
    "            # set current clade as child of parent_clade\n",
    "            parent_clade.clades.append(clade)\n",
    "            # update bitstring\n",
    "            # parent = parent ^ bitstr\n",
    "            # update clade\n",
    "            bitstr_clades[parent_bitstr] = parent_clade\n",
    "\n",
    "        if child_bitstrs:\n",
    "            remove_list = []\n",
    "            for c in child_bitstrs:\n",
    "                remove_list.extend(c.index_one())\n",
    "                child_clade = bitstr_clades[c]\n",
    "                parent_clade.clades.remove(child_clade)\n",
    "                clade.clades.append(child_clade)\n",
    "            remove_terms = [terms[i] for i in remove_list]\n",
    "            clade.clades = [c for c in clade.clades if c not in remove_terms]\n",
    "        # put new clade\n",
    "        bitstr_clades[bitstr] = clade\n",
    "        if (len(bitstr_clades) == len(terms) - 1) or (\n",
    "            len(bitstr_clades) == len(terms) - 2 and len(root.clades) == 3\n",
    "        ):\n",
    "            break\n",
    "    return BaseTree.Tree(root=root)\n",
    "\n",
    "\n",
    "def adam_consensus(trees):\n",
    "    \"\"\"Search Adam Consensus tree from multiple trees.\n",
    "    :Parameters:\n",
    "        trees : list\n",
    "            list of trees to produce consensus tree.\n",
    "    \"\"\"\n",
    "    clades = [tree.root for tree in trees]\n",
    "    return BaseTree.Tree(root=_part(clades), rooted=True)\n",
    "\n",
    "\n",
    "def _part(clades):\n",
    "    \"\"\"Recursive function for Adam Consensus algorithm (PRIVATE).\"\"\"\n",
    "    new_clade = None\n",
    "    terms = clades[0].get_terminals()\n",
    "    term_names = [term.name for term in terms]\n",
    "    if len(terms) == 1 or len(terms) == 2:\n",
    "        new_clade = clades[0]\n",
    "    else:\n",
    "        bitstrs = {_BitString(\"1\" * len(terms))}\n",
    "        for clade in clades:\n",
    "            for child in clade.clades:\n",
    "                bitstr = _clade_to_bitstr(child, term_names)\n",
    "                to_remove = set()\n",
    "                to_add = set()\n",
    "                for bs in bitstrs:\n",
    "                    if bs == bitstr:\n",
    "                        continue\n",
    "                    elif bs.contains(bitstr):\n",
    "                        to_add.add(bitstr)\n",
    "                        to_add.add(bs ^ bitstr)\n",
    "                        to_remove.add(bs)\n",
    "                    elif bitstr.contains(bs):\n",
    "                        to_add.add(bs ^ bitstr)\n",
    "                    elif not bs.independent(bitstr):\n",
    "                        to_add.add(bs & bitstr)\n",
    "                        to_add.add(bs & bitstr ^ bitstr)\n",
    "                        to_add.add(bs & bitstr ^ bs)\n",
    "                        to_remove.add(bs)\n",
    "                # bitstrs = bitstrs | to_add\n",
    "                bitstrs ^= to_remove\n",
    "                if to_add:\n",
    "                    for ta in sorted(to_add, key=lambda bs: bs.count(\"1\")):\n",
    "                        independent = True\n",
    "                        for bs in bitstrs:\n",
    "                            if not ta.independent(bs):\n",
    "                                independent = False\n",
    "                                break\n",
    "                        if independent:\n",
    "                            bitstrs.add(ta)\n",
    "        new_clade = BaseTree.Clade()\n",
    "        for bitstr in sorted(bitstrs):\n",
    "            indices = bitstr.index_one()\n",
    "            if len(indices) == 1:\n",
    "                new_clade.clades.append(terms[indices[0]])\n",
    "            elif len(indices) == 2:\n",
    "                bifur_clade = BaseTree.Clade()\n",
    "                bifur_clade.clades.append(terms[indices[0]])\n",
    "                bifur_clade.clades.append(terms[indices[1]])\n",
    "                new_clade.clades.append(bifur_clade)\n",
    "            elif len(indices) > 2:\n",
    "                part_names = [term_names[i] for i in indices]\n",
    "                next_clades = []\n",
    "                for clade in clades:\n",
    "                    next_clades.append(_sub_clade(clade, part_names))\n",
    "                # next_clades = [clade.common_ancestor([clade.find_any(name=name) for name in part_names]) for clade in clades]\n",
    "                new_clade.clades.append(_part(next_clades))\n",
    "    return new_clade\n",
    "\n",
    "\n",
    "def _sub_clade(clade, term_names):\n",
    "    \"\"\"Extract a compatible subclade that only contains the given terminal names (PRIVATE).\"\"\"\n",
    "    term_clades = [clade.find_any(name) for name in term_names]\n",
    "    sub_clade = clade.common_ancestor(term_clades)\n",
    "    if len(term_names) != sub_clade.count_terminals():\n",
    "        temp_clade = BaseTree.Clade()\n",
    "        temp_clade.clades.extend(term_clades)\n",
    "        for c in sub_clade.find_clades(terminal=False, order=\"preorder\"):\n",
    "            if c == sub_clade.root:\n",
    "                continue\n",
    "            childs = set(c.find_clades(terminal=True)) & set(term_clades)\n",
    "            if childs:\n",
    "                for tc in temp_clade.find_clades(terminal=False, order=\"preorder\"):\n",
    "                    tc_childs = set(tc.clades)\n",
    "                    tc_new_clades = tc_childs - childs\n",
    "                    if childs.issubset(tc_childs) and tc_new_clades:\n",
    "                        tc.clades = list(tc_new_clades)\n",
    "                        child_clade = BaseTree.Clade()\n",
    "                        child_clade.clades.extend(list(childs))\n",
    "                        tc.clades.append(child_clade)\n",
    "        sub_clade = temp_clade\n",
    "    return sub_clade\n",
    "\n",
    "\n",
    "def _count_clades(trees):\n",
    "    \"\"\"Count distinct clades (different sets of terminal names) in the trees (PRIVATE).\n",
    "    Return a tuple first a dict of bitstring (representing clade) and a tuple of its count of\n",
    "    occurrences and sum of branch length for that clade, second the number of trees processed.\n",
    "    :Parameters:\n",
    "        trees : iterable\n",
    "            An iterable that returns the trees to count\n",
    "    \"\"\"\n",
    "    bitstrs = {}\n",
    "    tree_count = 0\n",
    "    for tree in trees:\n",
    "        tree_count += 1\n",
    "        clade_bitstrs = _tree_to_bitstrs(tree)\n",
    "        for clade in tree.find_clades(terminal=False):\n",
    "            bitstr = clade_bitstrs[clade]\n",
    "            if bitstr in bitstrs:\n",
    "                count, sum_bl = bitstrs[bitstr]\n",
    "                count += 1\n",
    "                sum_bl += clade.branch_length or 0\n",
    "                bitstrs[bitstr] = (count, sum_bl)\n",
    "            else:\n",
    "                bitstrs[bitstr] = (1, clade.branch_length or 0)\n",
    "    return bitstrs, tree_count\n",
    "\n",
    "\n",
    "def get_support(target_tree, trees, len_trees=None):\n",
    "    \"\"\"Calculate branch support for a target tree given bootstrap replicate trees.\n",
    "    :Parameters:\n",
    "        target_tree : Tree\n",
    "            tree to calculate branch support for.\n",
    "        trees : iterable\n",
    "            iterable of trees used to calculate branch support.\n",
    "        len_trees : int\n",
    "            optional count of replicates in trees. len_trees must be provided\n",
    "            when len(trees) is not a valid operation.\n",
    "    \"\"\"\n",
    "    term_names = sorted(term.name for term in target_tree.find_clades(terminal=True))\n",
    "    bitstrs = {}\n",
    "\n",
    "    size = len_trees\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(trees)\n",
    "        except TypeError:\n",
    "            raise TypeError(\n",
    "                \"Trees does not support len(trees), \"\n",
    "                \"you must provide the number of replicates in trees \"\n",
    "                \"as the optional parameter len_trees.\"\n",
    "            ) from None\n",
    "\n",
    "    for clade in target_tree.find_clades(terminal=False):\n",
    "        bitstr = _clade_to_bitstr(clade, term_names)\n",
    "        bitstrs[bitstr] = (clade, 0)\n",
    "    for tree in trees:\n",
    "        for clade in tree.find_clades(terminal=False):\n",
    "            bitstr = _clade_to_bitstr(clade, term_names)\n",
    "            if bitstr in bitstrs:\n",
    "                c, t = bitstrs[bitstr]\n",
    "                c.confidence = (t + 1) * 100.0 / size\n",
    "                bitstrs[bitstr] = (c, t + 1)\n",
    "    return target_tree\n",
    "\n",
    "\n",
    "def bootstrap(msa, times):\n",
    "    \"\"\"Generate bootstrap replicates from a multiple sequence alignment object.\n",
    "    :Parameters:\n",
    "        msa : MultipleSeqAlignment\n",
    "            multiple sequence alignment to generate replicates.\n",
    "        times : int\n",
    "            number of bootstrap times.\n",
    "    \"\"\"\n",
    "    length = len(msa[0])\n",
    "    i = 0\n",
    "    while i < times:\n",
    "        i += 1\n",
    "        item = None\n",
    "        for j in range(length):\n",
    "            col = random.randint(0, length - 1)\n",
    "            if not item:\n",
    "                item = msa[:, col : col + 1]\n",
    "            else:\n",
    "                item += msa[:, col : col + 1]\n",
    "        yield item\n",
    "\n",
    "\n",
    "def bootstrap_trees(msa, times, tree_constructor):\n",
    "    \"\"\"Generate bootstrap replicate trees from a multiple sequence alignment.\n",
    "    :Parameters:\n",
    "        msa : MultipleSeqAlignment\n",
    "            multiple sequence alignment to generate replicates.\n",
    "        times : int\n",
    "            number of bootstrap times.\n",
    "        tree_constructor : TreeConstructor\n",
    "            tree constructor to be used to build trees.\n",
    "    \"\"\"\n",
    "    msas = bootstrap(msa, times)\n",
    "    for aln in msas:\n",
    "        tree = tree_constructor.build_tree(aln)\n",
    "        yield tree\n",
    "\n",
    "\n",
    "def bootstrap_consensus(msa, times, tree_constructor, consensus):\n",
    "    \"\"\"Consensus tree of a series of bootstrap trees for a multiple sequence alignment.\n",
    "    :Parameters:\n",
    "        msa : MultipleSeqAlignment\n",
    "            Multiple sequence alignment to generate replicates.\n",
    "        times : int\n",
    "            Number of bootstrap times.\n",
    "        tree_constructor : TreeConstructor\n",
    "            Tree constructor to be used to build trees.\n",
    "        consensus : function\n",
    "            Consensus method in this module: ``strict_consensus``,\n",
    "            ``majority_consensus``, ``adam_consensus``.\n",
    "    \"\"\"\n",
    "    trees = bootstrap_trees(msa, times, tree_constructor)\n",
    "    tree = consensus(list(trees))\n",
    "    return tree\n",
    "\n",
    "\n",
    "def _clade_to_bitstr(clade, tree_term_names):\n",
    "    \"\"\"Create a BitString representing a clade, given ordered tree taxon names (PRIVATE).\"\"\"\n",
    "    clade_term_names = {term.name for term in clade.find_clades(terminal=True)}\n",
    "    return _BitString.from_bool((name in clade_term_names) for name in tree_term_names)\n",
    "\n",
    "\n",
    "def _tree_to_bitstrs(tree):\n",
    "    \"\"\"Create a dict of a tree's clades to corresponding BitStrings (PRIVATE).\"\"\"\n",
    "    clades_bitstrs = {}\n",
    "    term_names = [term.name for term in tree.find_clades(terminal=True)]\n",
    "    for clade in tree.find_clades(terminal=False):\n",
    "        bitstr = _clade_to_bitstr(clade, term_names)\n",
    "        clades_bitstrs[clade] = bitstr\n",
    "    return clades_bitstrs\n",
    "\n",
    "\n",
    "def _bitstring_topology(tree):\n",
    "    \"\"\"Generate a branch length dict for a tree, keyed by BitStrings (PRIVATE).\n",
    "    Create a dict of all clades' BitStrings to the corresponding branch\n",
    "    lengths (rounded to 5 decimal places).\n",
    "    \"\"\"\n",
    "    bitstrs = {}\n",
    "    for clade, bitstr in _tree_to_bitstrs(tree).items():\n",
    "        bitstrs[bitstr] = round(clade.branch_length or 0.0, 5)\n",
    "    return bitstrs\n",
    "\n",
    "\n",
    "def _equal_topology(tree1, tree2):\n",
    "    \"\"\"Are two trees are equal in terms of topology and branch lengths (PRIVATE).\n",
    "    (Branch lengths checked to 5 decimal places.)\n",
    "    \"\"\"\n",
    "    term_names1 = {term.name for term in tree1.find_clades(terminal=True)}\n",
    "    term_names2 = {term.name for term in tree2.find_clades(terminal=True)}\n",
    "    return (term_names1 == term_names2) and (\n",
    "        _bitstring_topology(tree1) == _bitstring_topology(tree2)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
